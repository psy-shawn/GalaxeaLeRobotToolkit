import cv2
import numpy as np
from pyorbbecsdk import *
import time
import threading
from queue import Queue
import os
from datetime import datetime
VIDEO_FPS = 15.0
def setup_camera_pipeline(device, camera_index):
    """ä¸ºå•å°ç›¸æœºé…ç½®å¹¶å¯åŠ¨Pipeline"""
    device_info = device.get_device_info()
    serial = device_info.get_serial_number()
    
    print(f"æ­£åœ¨é…ç½®ç›¸æœº {camera_index}: åºåˆ—å· {serial}")
    
    # åˆ›å»ºPipeline
    pipeline = Pipeline(device)
    config = Config()
    
    success = True
    error_msgs = []
    
    try:
        # é…ç½®Depthæµ
        depth_profile_list = pipeline.get_stream_profile_list(OBSensorType.DEPTH_SENSOR)
        if depth_profile_list is not None:
            depth_profile = depth_profile_list.get_video_stream_profile(640, 400, OBFormat.Y16, int(VIDEO_FPS))
            if depth_profile:
                config.enable_stream(depth_profile)
                print(f"  ç›¸æœº{camera_index}: æ·±åº¦æµ 640x400 Y16 @{int(VIDEO_FPS)}fps")
            else:
                default_depth_profile = depth_profile_list.get_default_video_stream_profile()
                config.enable_stream(default_depth_profile)
                print(f"  ç›¸æœº{camera_index}: ä½¿ç”¨é»˜è®¤æ·±åº¦æµé…ç½®")
        else:
            error_msgs.append(f"ç›¸æœº{camera_index}: ä¸æ”¯æŒæ·±åº¦æµ")
            success = False
    except Exception as e:
        error_msgs.append(f"ç›¸æœº{camera_index}: æ·±åº¦æµé…ç½®å¼‚å¸¸ - {str(e)[:50]}")
        success = False
    
    try:
        # é…ç½®Coloræµ
        color_profile_list = pipeline.get_stream_profile_list(OBSensorType.COLOR_SENSOR)
        if color_profile_list is not None:
            color_profile = color_profile_list.get_video_stream_profile(640, 480, OBFormat.RGB, int(VIDEO_FPS))
            if color_profile:
                config.enable_stream(color_profile)
                print(f"  ç›¸æœº{camera_index}: å½©è‰²æµ 640x480 RGB @{int(VIDEO_FPS)}fps")
            else:
                default_color_profile = color_profile_list.get_default_video_stream_profile()
                config.enable_stream(default_color_profile)
                print(f"  ç›¸æœº{camera_index}: ä½¿ç”¨é»˜è®¤å½©è‰²æµé…ç½®")
        else:
            error_msgs.append(f"ç›¸æœº{camera_index}: ä¸æ”¯æŒå½©è‰²æµ")
            success = False
    except Exception as e:
        error_msgs.append(f"ç›¸æœº{camera_index}: å½©è‰²æµé…ç½®å¼‚å¸¸ - {str(e)[:50]}")
        success = False
    
    # å¯åŠ¨pipeline
    if success:
        try:
            pipeline.start(config)
            print(f"âœ… ç›¸æœº {camera_index} å¯åŠ¨æˆåŠŸ")
            return {
                'pipeline': pipeline,
                'serial': serial,
                'index': camera_index,
                'errors': []
            }
        except Exception as e:
            error_msgs.append(f"ç›¸æœº{camera_index}: å¯åŠ¨å¤±è´¥ - {str(e)[:50]}")
    
    # å¦‚æœæœ‰é”™è¯¯ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
    return {
        'pipeline': None,
        'serial': serial,
        'index': camera_index,
        'errors': error_msgs
    }

def camera_capture_worker(pipeline_info, frame_queue, stop_event):
    """ç›¸æœºæ•è·å·¥ä½œçº¿ç¨‹"""
    pipeline = pipeline_info['pipeline']
    camera_index = pipeline_info['index']
    serial = pipeline_info['serial']
    
    frame_count = 0
    last_log_time = time.time()
    consecutive_timeouts = 0  # æ·»åŠ è¿ç»­è¶…æ—¶è®¡æ•°
    
    while not stop_event.is_set():
        try:
            # ç­‰å¾…åŒæ­¥å¸§ - å‡å°‘è¶…æ—¶æ—¶é—´ä»¥ä¾¿æ›´å¿«å‘ç°é—®é¢˜
            frames = pipeline.wait_for_frames(500)  # æ”¹ä¸º500msè¶…æ—¶
            if frames is None:
                consecutive_timeouts += 1
                # æ¯5æ¬¡è¾“å‡ºä¸€æ¬¡è°ƒè¯•ä¿¡æ¯
                if consecutive_timeouts % 5 == 0:
                    print(f"âš ï¸ ç›¸æœº{camera_index} (SN:{serial[-6:]}) ç­‰å¾…å¸§è¶…æ—¶ {consecutive_timeouts}æ¬¡")
                continue
            
            # é‡ç½®è¶…æ—¶è®¡æ•°
            consecutive_timeouts = 0
            
            color_frame = frames.get_color_frame()
            depth_frame = frames.get_depth_frame()
            
            if color_frame is None:
                frame_count_debug = getattr(camera_capture_worker, 'debug_color', 0) + 1
                camera_capture_worker.debug_color = frame_count_debug
                if frame_count_debug % 50 == 0:
                    print(f"âš ï¸ ç›¸æœº{camera_index}color_frameä¸ºNone (debug#{frame_count_debug})")
                continue
            
            if depth_frame is None:
                frame_count_debug = getattr(camera_capture_worker, 'debug_depth', 0) + 1
                camera_capture_worker.debug_depth = frame_count_debug
                if frame_count_debug % 50 == 0:
                    print(f"âš ï¸ ç›¸æœº{camera_index}depth_frameä¸ºNone (debug#{frame_count_debug})")
                continue
            
            # å¤„ç†å½©è‰²å¸§
            color_data = np.frombuffer(color_frame.get_data(), dtype=np.uint8)
            color_width = color_frame.get_width()
            color_height = color_frame.get_height()
            
            if color_frame.get_format() == OBFormat.RGB:
                color_data = color_data.reshape((color_height, color_width, 3))
                color_image = cv2.cvtColor(color_data, cv2.COLOR_RGB2BGR)
            else:
                color_data = color_data.reshape((color_height, color_width, -1))
                color_image = color_data
            
            # å¤„ç†æ·±åº¦å¸§
            depth_data = np.frombuffer(depth_frame.get_data(), dtype=np.uint16)
            depth_width = depth_frame.get_width()
            depth_height = depth_frame.get_height()
            
            if len(depth_data) > 0:
                depth_data = depth_data.reshape((depth_height, depth_width))
                depth_normalized = cv2.normalize(depth_data, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)
                depth_image = cv2.applyColorMap(depth_normalized, cv2.COLORMAP_JET)
            else:
                depth_image = np.zeros((depth_height, depth_width, 3), dtype=np.uint8)
            
            # è°ƒæ•´æ·±åº¦å›¾å°ºå¯¸ä»¥åŒ¹é…å½©è‰²å›¾
            if depth_image.shape[:2] != color_image.shape[:2]:
                depth_image = cv2.resize(depth_image, (color_image.shape[1], color_image.shape[0]))
            
            # æ°´å¹³æ‹¼æ¥
            combined = np.hstack((color_image, depth_image))
            
            # æ·»åŠ ç›¸æœºä¿¡æ¯
            cv2.putText(combined, f"Cam{camera_index}: {serial[-6:]}", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(combined, f"Frame: {frame_count}", 
                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # æ·»åŠ æ—¶é—´æˆ³
            timestamp = color_frame.get_timestamp()
            cv2.putText(combined, f"TS: {timestamp/1e6:.2f}ms", 
                       (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            # æ·»åŠ åˆ°é˜Ÿåˆ—
            frame_queue.put({
                'camera_index': camera_index,
                'frame': combined,
                'frame_count': frame_count,
                'timestamp': timestamp
            })
            
            frame_count += 1
            
            # æ¯2ç§’è¾“å‡ºä¸€æ¬¡çŠ¶æ€
            current_time = time.time()
            if current_time - last_log_time > 2.0:
                fps = frame_count / (current_time - last_log_time) if frame_count > 0 else 0
                print(f"ç›¸æœº{camera_index}: {frame_count}å¸§, å®æ—¶FPS: {fps:.1f}")
                frame_count = 0
                last_log_time = current_time
                
        except Exception as e:
            print(f"ç›¸æœº{camera_index}æ•è·å¼‚å¸¸: {e}")
            time.sleep(0.1)
    
    print(f"ç›¸æœº{camera_index}æ•è·çº¿ç¨‹ç»“æŸ")

def main():
    # åˆå§‹åŒ–ä¸Šä¸‹æ–‡
    ctx = Context()
    device_list = ctx.query_devices()
    
    if device_list.get_count() == 0:
        print("âŒ æœªå‘ç°ç›¸æœºï¼Œè¯·æ£€æŸ¥USBè¿æ¥")
        return
    
    print(f"âœ… æ£€æµ‹åˆ° {device_list.get_count()} å°ç›¸æœº")
    
    # åŒæ—¶é…ç½®å’Œå¯åŠ¨æ‰€æœ‰ç›¸æœº
    print("\nğŸš€ æ­£åœ¨åŒæ—¶å¯åŠ¨æ‰€æœ‰ç›¸æœº...")
    pipelines = []
    
    for i in range(device_list.get_count()):
        device = device_list.get_device_by_index(i)
        pipeline_info = setup_camera_pipeline(device, i)
        
        if pipeline_info['pipeline'] is not None:
            pipelines.append(pipeline_info)
        else:
            print(f"âŒ ç›¸æœº{i}é…ç½®å¤±è´¥: {pipeline_info['errors']}")
    
    if not pipelines:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„ç›¸æœºé…ç½®ï¼Œé€€å‡º")
        return
    
    print(f"\nğŸ¯ æˆåŠŸå¯åŠ¨ {len(pipelines)} å°ç›¸æœº")
    
    # åˆ›å»ºå¸§é˜Ÿåˆ—å’Œåœæ­¢äº‹ä»¶
    frame_queue = Queue(maxsize=20)
    stop_event = threading.Event()
    
    # å¯åŠ¨æ•è·çº¿ç¨‹
    capture_threads = []
    for pipeline_info in pipelines:
        thread = threading.Thread(
            target=camera_capture_worker,
            args=(pipeline_info, frame_queue, stop_event),
            daemon=True
        )
        thread.start()
        capture_threads.append(thread)
        print(f"ğŸ“¹ å¯åŠ¨ç›¸æœº{pipeline_info['index']}æ•è·çº¿ç¨‹")
    
    print("\nğŸ¬ åŒç›¸æœºåŒæ­¥è¿è¡Œä¸­...")
    print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print("æ§åˆ¶æŒ‡ä»¤:")
    print("  â€¢ æŒ‰ 'q' æˆ– ESC é”® - é€€å‡ºç¨‹åº")
    print("  â€¢ æŒ‰ 's' é”® - ä¿å­˜å½“å‰å¸§åˆ°æ–‡ä»¶")
    print("  â€¢ æŒ‰ 'p' é”® - æš‚åœ/ç»§ç»­æ˜¾ç¤º")
    print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    # åˆ›å»ºæ˜¾ç¤ºçª—å£
    window_names = []
    for pipeline_info in pipelines:
        window_name = f"Camera {pipeline_info['index']} - {pipeline_info['serial'][-6:]}"
        window_names.append(window_name)
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(window_name, 640, 240)  # è®¾ç½®çª—å£å¤§å°

        # =========== ğŸ‘‡ åœ¨è¿™é‡Œæ·»åŠ ä½ç½®è®¾ç½®ä»£ç  ğŸ‘‡ ===========
        # æ ¹æ®ç›¸æœºç´¢å¼•(index)è®¡ç®—çºµå‘ä½ç½®
        # 50æ˜¯èµ·å§‹Yåæ ‡ï¼Œ520æ˜¯å‚ç›´é—´è·ï¼ˆçª—å£é«˜åº¦480 + æ ‡é¢˜æ é—´éš”40ï¼‰
        x_pos = 5 
        y_pos = 5 + (pipeline_info['index'] * 520) 
        
        cv2.moveWindow(window_name, x_pos, y_pos)
        # =================================================
    # ä¸»æ˜¾ç¤ºå¾ªç¯
    display_enabled = True
    last_fps_time = time.time()
    fps_frame_count = 0
    
    try:
        while True:
            # å¤„ç†æ‰€æœ‰å¾…æ˜¾ç¤ºçš„å¸§
            frames_to_display = {}
            while not frame_queue.empty():
                frame_data = frame_queue.get_nowait()
                frames_to_display[frame_data['camera_index']] = frame_data
            
            # æ˜¾ç¤ºå¸§
            if display_enabled and frames_to_display:
                for camera_index, frame_data in frames_to_display.items():
                    window_name = window_names[camera_index]
                    cv2.imshow(window_name, frame_data['frame'])
                
                fps_frame_count += 1
            
            # è®¡ç®—å¹¶æ˜¾ç¤ºFPS
            current_time = time.time()
            if current_time - last_fps_time >= 1.0:
                fps = fps_frame_count / (current_time - last_fps_time)
                print(f"\rğŸ“Š æ˜¾ç¤ºFPS: {fps:.1f} | æŒ‰'q'é€€å‡º | é˜Ÿåˆ—å¤§å°: {frame_queue.qsize()}", end="")
                fps_frame_count = 0
                last_fps_time = current_time
            
            # é”®ç›˜æ§åˆ¶
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('q') or key == 27:  # 'q' æˆ– ESC
                print("\n\nğŸ›‘ ç”¨æˆ·è¯·æ±‚é€€å‡º")
                break
            elif key == ord('s'):  # ä¿å­˜å½“å‰å¸§
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
                save_dir = "saved_frames"
                os.makedirs(save_dir, exist_ok=True)
                
                for camera_index, frame_data in frames_to_display.items():
                    filename = f"{save_dir}/cam{camera_index}_{timestamp}.png"
                    cv2.imwrite(filename, frame_data['frame'])
                    print(f"ğŸ’¾ ä¿å­˜ç›¸æœº{camera_index}å¸§: {filename}")
                
                # æ·»åŠ çŸ­æš‚å»¶è¿Ÿé˜²æ­¢é‡å¤ä¿å­˜
                time.sleep(0.3)
            elif key == ord('p'):  # æš‚åœ/ç»§ç»­æ˜¾ç¤º
                display_enabled = not display_enabled
                status = "ç»§ç»­" if display_enabled else "æš‚åœ"
                print(f"\nâ¸ï¸  æ˜¾ç¤º{status}")
                
                # æš‚åœæ—¶æ˜¾ç¤ºçº¯è‰²ç”»é¢
                if not display_enabled:
                    for window_name in window_names:
                        blank_frame = np.zeros((480, 1280, 3), dtype=np.uint8)
                        cv2.putText(blank_frame, "æ˜¾ç¤ºå·²æš‚åœ", 
                                   (500, 240), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                        cv2.putText(blank_frame, "æŒ‰ 'p' é”®ç»§ç»­", 
                                   (470, 280), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                        cv2.imshow(window_name, blank_frame)
            
            # æ§åˆ¶å¾ªç¯é¢‘ç‡
            time.sleep(0.001)
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·")
    except Exception as e:
        print(f"\n\nâŒ è¿è¡Œæ—¶é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # åœæ­¢æ‰€æœ‰çº¿ç¨‹
        print("\nğŸ›‘ æ­£åœ¨åœæ­¢æ‰€æœ‰ç›¸æœº...")
        stop_event.set()
        
        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        for thread in capture_threads:
            thread.join(timeout=2.0)
        
        # åœæ­¢æ‰€æœ‰pipeline
        print("æ­£åœ¨é‡Šæ”¾ç›¸æœºèµ„æº...")
        for pipeline_info in pipelines:
            if pipeline_info['pipeline']:
                try:
                    pipeline_info['pipeline'].stop()
                    print(f"âœ… ç›¸æœº{pipeline_info['index']}å·²åœæ­¢")
                except Exception as e:
                    print(f"âŒ åœæ­¢ç›¸æœº{pipeline_info['index']}æ—¶å‡ºé”™: {e}")
        
        # å…³é—­æ‰€æœ‰çª—å£
        cv2.destroyAllWindows()
        
        # æ¸…ç©ºé˜Ÿåˆ—
        while not frame_queue.empty():
            try:
                frame_queue.get_nowait()
            except:
                pass
        
        print("\nğŸ‰ ç¨‹åºç»“æŸï¼Œæ‰€æœ‰èµ„æºå·²é‡Šæ”¾")

if __name__ == "__main__":
    main()