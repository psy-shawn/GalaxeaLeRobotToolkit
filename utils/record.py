import cv2
import numpy as np
from pyorbbecsdk import *
import time
import os
import csv
from datetime import datetime
import argparse
import json
import shutil  # ç”¨äºåˆ é™¤æ–‡ä»¶å¤¹

# å…¨å±€é…ç½®
SAVE_ROOT = "./recordings"
# è§†é¢‘ç¼–ç é…ç½®
VIDEO_CODEC = 'mp4v'  # å¯é€‰: 'mp4v', 'avc1', 'XVID'
VIDEO_EXT = '.mp4'
# å¯é…ç½®å¸§ç‡
VIDEO_FPS = 15.0

# åŒæ­¥é…ç½®æ–‡ä»¶è·¯å¾„
CONFIG_FILE_PATH = "/Users/psy/workspace/GalaxeaLeRobotToolkit/utils/multi_device_sync_config.json"


def sync_mode_from_str(sync_mode_str):
    """è½¬æ¢åŒæ­¥æ¨¡å¼å­—ç¬¦ä¸²ä¸ºæšä¸¾å€¼"""
    sync_mode_str = sync_mode_str.upper()
    if sync_mode_str == "FREE_RUN":
        return OBMultiDeviceSyncMode.FREE_RUN
    elif sync_mode_str == "STANDALONE":
        return OBMultiDeviceSyncMode.STANDALONE
    elif sync_mode_str == "PRIMARY":
        return OBMultiDeviceSyncMode.PRIMARY
    elif sync_mode_str == "SECONDARY":
        return OBMultiDeviceSyncMode.SECONDARY
    elif sync_mode_str == "SECONDARY_SYNCED":
        return OBMultiDeviceSyncMode.SECONDARY_SYNCED
    elif sync_mode_str == "SOFTWARE_TRIGGERING":
        return OBMultiDeviceSyncMode.SOFTWARE_TRIGGERING
    elif sync_mode_str == "HARDWARE_TRIGGERING":
        return OBMultiDeviceSyncMode.HARDWARE_TRIGGERING
    else:
        return OBMultiDeviceSyncMode.FREE_RUN


def setup_pipeline(device, serial, sync_config_dict=None):
    """ä¸ºæŒ‡å®šè®¾å¤‡åˆ›å»ºå¹¶é…ç½®Pipeline"""
    pipeline = Pipeline(device)
    config = Config()

    # é…ç½®åŒæ­¥æ¨¡å¼
    if sync_config_dict:
        try:
            sync_config = device.get_multi_device_sync_config()
            sync_config.mode = sync_mode_from_str(sync_config_dict.get("mode", "FREE_RUN"))
            sync_config.color_delay_us = sync_config_dict.get("color_delay_us", 0)
            sync_config.depth_delay_us = sync_config_dict.get("depth_delay_us", 0)
            sync_config.trigger_out_enable = sync_config_dict.get("trigger_out_enable", False)
            sync_config.trigger_out_delay_us = sync_config_dict.get("trigger_out_delay_us", 0)
            sync_config.frames_per_trigger = sync_config_dict.get("frames_per_trigger", 1)

            device.set_multi_device_sync_config()
            print(f"  [åŒæ­¥] æ¨¡å¼: {sync_config_dict.get('mode', 'FREE_RUN')}")
        except Exception as e:
            print(f"  [åŒæ­¥] é…ç½®å¤±è´¥: {e}")

    try:
        # å¯ç”¨æ·±åº¦æµ
        depth_profile_list = pipeline.get_stream_profile_list(OBSensorType.DEPTH_SENSOR)
        if depth_profile_list is not None:
            depth_profile = depth_profile_list.get_video_stream_profile(640, 400, OBFormat.Y16, int(VIDEO_FPS))
            if depth_profile:
                config.enable_stream(depth_profile)
                print(f"  [æ·±åº¦] 640x400 Y16 @{int(VIDEO_FPS)}fps")
            else:
                default_depth_profile = depth_profile_list.get_default_video_stream_profile()
                config.enable_stream(default_depth_profile)
                print(f"  [æ·±åº¦] é»˜è®¤é…ç½®")
    except Exception as e:
        print(f"  æ·±åº¦æµé…ç½®å¼‚å¸¸: {e}")
    
    try:
        # å¯ç”¨å½©è‰²æµ
        color_profile_list = pipeline.get_stream_profile_list(OBSensorType.COLOR_SENSOR)
        if color_profile_list is not None:
            color_profile = color_profile_list.get_video_stream_profile(640, 480, OBFormat.RGB, int(VIDEO_FPS))
            if color_profile:
                config.enable_stream(color_profile)
                print(f"  [å½©è‰²] 640x480 RGB @{int(VIDEO_FPS)}fps")
            else:
                default_color_profile = color_profile_list.get_default_video_stream_profile()
                config.enable_stream(default_color_profile)
                print(f"  [å½©è‰²] é»˜è®¤é…ç½®")
    except Exception as e:
        print(f"  å½©è‰²æµé…ç½®å¼‚å¸¸: {e}")
    
    pipeline.start(config)
    return pipeline

def main():
    parser = argparse.ArgumentParser(description="Record from Orbbec cameras")
    parser.add_argument('--no-display', action='store_true', help='run in headless mode without GUI display')
    args = parser.parse_args()
    no_display = args.no_display

    # åˆå§‹åŒ–
    ctx = Context()
    device_list = ctx.query_devices()
    
    if device_list.get_count() == 0:
        print("âŒ æœªæ£€æµ‹åˆ°å¥¥æ¯”ä¸­å…‰è®¾å¤‡")
        return
    
    print(f"âœ… æ£€æµ‹åˆ° {device_list.get_count()} å°ç›¸æœº")
    print(f"ğŸ“¹ è§†é¢‘ç¼–ç : {VIDEO_CODEC} ({VIDEO_EXT})")

    # åŠ è½½åŒæ­¥é…ç½®
    sync_configs = {}
    if os.path.exists(CONFIG_FILE_PATH):
        try:
            with open(CONFIG_FILE_PATH, 'r') as f:
                config_data = json.load(f)
                for device in config_data.get("devices", []):
                    serial = device.get("serial_number", "")
                    if serial:
                        sync_configs[serial] = device.get("config", {})
            print("ğŸ“„ å·²åŠ è½½åŒæ­¥é…ç½®æ–‡ä»¶")
        except Exception as e:
            print(f"âš ï¸  åŠ è½½åŒæ­¥é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    else:
        print("â„¹ï¸  æœªæ‰¾åˆ°åŒæ­¥é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨FREE_RUNæ¨¡å¼")

    # åˆ›å»ºæ ¹ç›®å½•
    if not os.path.exists(SAVE_ROOT):
        os.makedirs(SAVE_ROOT)
    
    recorders = []
    timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
    # æœ¬æ¬¡ä¼šè¯çš„æ€»ç›®å½•
    session_dir = os.path.join(SAVE_ROOT, timestamp_str)
    
    # æ ‡è®°æ˜¯å¦ä¿å­˜æ•°æ® (é»˜è®¤ä¸ºTrueï¼ŒCtrl+Xæ—¶æ”¹ä¸ºFalse)
    save_data_flag = True

    for i in range(device_list.get_count()):
        try:
            # 1. å…ˆå°è¯•è·å–è®¾å¤‡å¯¹è±¡
            # å¦‚æœè¿™è¡ŒæŠ¥é”™ï¼Œè¯´æ˜æ˜¯ç³»ç»Ÿå†…ç½®ç›¸æœºæˆ–æƒé™è¢«å ç”¨ï¼Œç›´æ¥è·³è¿‡
            device = device_list.get_device_by_index(i)
            
            # 2. è·å–è®¾å¤‡ä¿¡æ¯è¿›è¡ŒäºŒæ¬¡ç¡®è®¤
            info = device.get_device_info()
            name = info.get_name()
            serial = info.get_serial_number()
            
            # 3. è¿‡æ»¤éå¥¥æ¯”ä¸­å…‰è®¾å¤‡ï¼ˆå¯é€‰ï¼Œä½†å»ºè®®ä¿ç•™ï¼‰
            if "FaceTime" in name or "Apple" in name:
                print(f"â­ï¸  è·³è¿‡å†…ç½®è®¾å¤‡: {name}")
                continue
                
        except Exception as e:
            # è¿™é‡Œä¼šæ•è·åˆ° uvc_open failed: -3
            print(f"âš ï¸  è·³è¿‡æ— æ³•è®¿é—®çš„è®¾å¤‡ (ç´¢å¼• {i}): {e}")
            continue

        print(f"\nğŸ¯ æ­£åœ¨åˆå§‹åŒ–ç›¸æœº {i} (SN: {serial})...")

    # # ä¸ºæ¯å°ç›¸æœºåˆå§‹åŒ–å½•åˆ¶å™¨
    # for i in range(device_list.get_count()):
    #     device = device_list.get_device_by_index(i)
    #     serial = device.get_device_info().get_serial_number()
        
    #     print(f"\nğŸ¯ æ­£åœ¨åˆå§‹åŒ–ç›¸æœº {i} (SN: {serial})...")
        
        # ç›¸æœºç‹¬ç«‹ç›®å½•
        cam_dir = os.path.join(session_dir, f"cam_{serial}")
        os.makedirs(cam_dir, exist_ok=True)
        # æ³¨æ„ï¼šè¿™é‡Œä¸å†éœ€è¦ depth_raw æ–‡ä»¶å¤¹ï¼Œå› ä¸ºæ”¹ä¸ºè§†é¢‘å½•åˆ¶äº†
        
        # é…ç½®å¹¶å¯åŠ¨pipeline
        device_sync_config = sync_configs.get(serial, {})
        pipeline = setup_pipeline(device, serial, device_sync_config)
        
        # --- RGB è§†é¢‘å†™å…¥å™¨ ---
        rgb_video_path = os.path.join(cam_dir, f"rgb_video{VIDEO_EXT}")
        fourcc = cv2.VideoWriter_fourcc(*VIDEO_CODEC)
        rgb_writer = cv2.VideoWriter(rgb_video_path, fourcc, float(VIDEO_FPS), (640, 480))
        
        if not rgb_writer.isOpened():
            print(f"âš ï¸  è­¦å‘Š: æ— æ³•åˆ›å»ºMP4è§†é¢‘æ–‡ä»¶ï¼Œå°è¯•ä½¿ç”¨XVIDç¼–ç ...")
            rgb_video_path = os.path.join(cam_dir, "rgb_video.avi")
            fourcc = cv2.VideoWriter_fourcc(*'XVID')
            rgb_writer = cv2.VideoWriter(rgb_video_path, fourcc, float(VIDEO_FPS), (640, 480))

        # --- Depth è§†é¢‘å†™å…¥å™¨ (æ–°å¢) ---
        # æ·±åº¦å›¾åˆ†è¾¨ç‡ä¸º 640x400 (è§ setup_pipeline)
        depth_video_path = os.path.join(cam_dir, f"depth_video{VIDEO_EXT}")
        # ä½¿ç”¨ç›¸åŒçš„ç¼–ç å™¨
        depth_writer = cv2.VideoWriter(depth_video_path, fourcc, float(VIDEO_FPS), (640, 400))
        
        # æ—¶é—´æˆ³CSVæ–‡ä»¶
        csv_path = os.path.join(cam_dir, "timestamps.csv")
        csv_file = open(csv_path, 'w', newline='')
        csv_writer = csv.writer(csv_file)
        csv_writer.writerow(["Frame_Index", "System_Timestamp_ns", "Device_Timestamp_us",
                           "RGB_Width", "RGB_Height", "Depth_Width", "Depth_Height", "Rel_Time_ms"])
        
        # æ·±åº¦å¸§ä¿¡æ¯CSV (ç¨å¾®è°ƒæ•´ï¼Œå› ä¸ºæ²¡æœ‰å•ä¸ªæ–‡ä»¶åäº†)
        depth_info_path = os.path.join(cam_dir, "depth_stats.csv")
        depth_info_file = open(depth_info_path, 'w', newline='')
        depth_info_writer = csv.writer(depth_info_file)
        depth_info_writer.writerow(["Frame_Index", "Min_Distance", "Max_Distance", 
                                  "Mean_Distance", "Valid_Pixels"])
        
        recorders.append({
            'pipeline': pipeline,
            'serial': serial,
            'index': i,
            'rgb_writer': rgb_writer,
            'depth_writer': depth_writer,
            'csv_file': csv_file,
            'csv_writer': csv_writer,
            'depth_info_file': depth_info_file,
            'depth_info_writer': depth_info_writer,
            'cam_dir': cam_dir,
            'frame_idx': 0,
            'video_path': rgb_video_path,
            'depth_video_path': depth_video_path
        })
        
        print(f"  å½•åˆ¶ç›®å½•: {cam_dir}")
    
    print(f"\nâºï¸  å¼€å§‹åŒæ­¥å½•åˆ¶ {len(recorders)} å°ç›¸æœº")
    if no_display:
        print("   headless mode. Use Ctrl-C to stop.")
    else:
        print("   æŒ‰ 'q' æˆ– 'Ctrl+Y' -> ä¿å­˜å¹¶é€€å‡º")
        print("   æŒ‰ 'Ctrl+X'        -> âŒ ä¸¢å¼ƒæ•°æ®å¹¶é€€å‡º")
        print("   æŒ‰ 'p'             -> æš‚åœ/ç»§ç»­")

    # çª—å£è®¾ç½®
    if not no_display:
        for rec in recorders:
            window_name = f"Camera {rec['index']} - {rec['serial'][-6:]}"
            cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
            cv2.resizeWindow(window_name, 640, 240)
            cv2.moveWindow(window_name, 5, 5 + (rec['index'] * 520))

    try:
        start_time = time.time()
        start_time_ns = time.time_ns()
        last_status_time = start_time
        recording_paused = False
        
        while True:
            # --- æŒ‰é”®æ§åˆ¶é€»è¾‘ ---
            if no_display:
                key = None
            else:
                key = cv2.waitKey(1) & 0xFF
            
            # å¤„ç†ç‰¹æ®ŠæŒ‰é”®
            if key == ord('q') or key == 25: # 25 is Ctrl+Y
                print("\nğŸ’¾ ç”¨æˆ·è¯·æ±‚åœæ­¢å¹¶ä¿å­˜...")
                save_data_flag = True
                break
            elif key == 24: # 24 is Ctrl+X
                print("\nğŸ—‘ï¸ ç”¨æˆ·è¯·æ±‚åœæ­¢å¹¶ [ä¸¢å¼ƒæ•°æ®]...")
                save_data_flag = False
                break
            elif key == ord('p'):
                recording_paused = not recording_paused
                print(f"\nâ¸ï¸  å½•åˆ¶{'å·²æš‚åœ' if recording_paused else 'å·²ç»§ç»­'}")
                cv2.waitKey(300)

            # æš‚åœé€»è¾‘
            if recording_paused:
                if not no_display:
                    for rec in recorders:
                        preview = np.zeros((480, 640*2, 3), dtype=np.uint8)
                        cv2.putText(preview, "PAUSED", (200, 240), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                        cv2.imshow(f"Camera {rec['index']} - {rec['serial'][-6:]}", preview)
                else:
                    time.sleep(0.1)
                continue
            
            # å¸§å¤„ç†
            frames_processed = 0
            for rec in recorders:
                pipeline = rec['pipeline']
                frames = pipeline.wait_for_frames(50)
                if frames is None: continue
                
                color_frame = frames.get_color_frame()
                depth_frame = frames.get_depth_frame()
                
                if color_frame is None or depth_frame is None: continue
                
                frame_idx = rec['frame_idx']
                
                # --- RGB å¤„ç† ---
                color_data = np.frombuffer(color_frame.get_data(), dtype=np.uint8)
                color_data = color_data.reshape((color_frame.get_height(), color_frame.get_width(), 3))
                bgr_image = cv2.cvtColor(color_data, cv2.COLOR_RGB2BGR)
                rec['rgb_writer'].write(bgr_image)
                
                # --- Depth å¤„ç† (è½¬ä¸ºè§†é¢‘) ---
                depth_data = np.frombuffer(depth_frame.get_data(), dtype=np.uint16)
                depth_data = depth_data.reshape((depth_frame.get_height(), depth_frame.get_width()))
                
                # 1. ç”Ÿæˆå¯è§†åŒ–å½©è‰²æ·±åº¦å›¾ç”¨äºä¿å­˜ä¸ºMP4 (å› ä¸ºMP4ä¸æ”¯æŒ16ä½ç°åº¦)
                # å½’ä¸€åŒ–: 0-255. ä¸ºäº†æ›´å¥½çš„å¯è§†åŒ–æ•ˆæœï¼Œå¯ä»¥æˆªæ–­è¿‡è¿œçš„è·ç¦»
                # è¿™é‡Œç®€å•åœ°åš MINMAX å½’ä¸€åŒ–
                depth_norm = cv2.normalize(depth_data, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)
                depth_colormap = cv2.applyColorMap(depth_norm, cv2.COLORMAP_JET)
                
                # å†™å…¥æ·±åº¦è§†é¢‘æ–‡ä»¶
                rec['depth_writer'].write(depth_colormap)
                
                # --- è®°å½•æ•°æ® ---
                sys_ts_ns = time.time_ns()
                dev_ts_us = color_frame.get_timestamp()
                rel_time_ms = (sys_ts_ns - start_time_ns) / 1e6

                rec['csv_writer'].writerow([
                    frame_idx, sys_ts_ns, dev_ts_us,
                    color_frame.get_width(), color_frame.get_height(),
                    depth_frame.get_width(), depth_frame.get_height(),
                    rel_time_ms
                ])
                
                # ç»Ÿè®¡ä¿¡æ¯
                valid_depth = depth_data[depth_data > 0]
                if len(valid_depth) > 0:
                    min_dist, max_dist = np.min(valid_depth), np.max(valid_depth)
                    mean_dist = np.mean(valid_depth)
                    valid_pixels = len(valid_depth)
                else:
                    min_dist = max_dist = mean_dist = valid_pixels = 0
                
                rec['depth_info_writer'].writerow([frame_idx, min_dist, max_dist, mean_dist, valid_pixels])
                
                # --- é¢„è§ˆæ˜¾ç¤º ---
                # ä¸ºäº†é¢„è§ˆä¸€è‡´ï¼Œè°ƒæ•´æ·±åº¦å›¾å¤§å°åŒ¹é…RGB
                if depth_colormap.shape[:2] != bgr_image.shape[:2]:
                    depth_display_resized = cv2.resize(depth_colormap, (bgr_image.shape[1], bgr_image.shape[0]))
                else:
                    depth_display_resized = depth_colormap
                    
                preview = np.hstack((bgr_image, depth_display_resized))
                
                info_text = f"Cam {rec['index']} | Fr: {frame_idx} | {rel_time_ms:.1f}ms"
                cv2.putText(preview, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                if not no_display:
                    cv2.imshow(f"Camera {rec['index']} - {rec['serial'][-6:]}", preview)
                
                rec['frame_idx'] += 1
                frames_processed += 1
            
            # å®šæ—¶çŠ¶æ€è¾“å‡º
            current_time = time.time()
            if current_time - last_status_time > 5 and frames_processed > 0:
                elapsed = current_time - start_time
                print(f"\rğŸ“Š å½•åˆ¶ä¸­: {elapsed:.1f}s | Ctrl+Y ä¿å­˜é€€å‡º | Ctrl+X ä¸¢å¼ƒé€€å‡º", end="")
                last_status_time = current_time
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼Œé»˜è®¤ä¿å­˜æ•°æ®")
    except Exception as e:
        print(f"\n\nâŒ å½•åˆ¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # --- æ¸…ç†èµ„æº ---
        print("\næ­£åœ¨é‡Šæ”¾èµ„æº...")
        if not no_display:
            cv2.destroyAllWindows()
            
        for rec in recorders:
            try:
                rec['pipeline'].stop()
                rec['rgb_writer'].release()
                rec['depth_writer'].release() # é‡Šæ”¾æ·±åº¦è§†é¢‘å†™å…¥å™¨
                rec['csv_file'].close()
                rec['depth_info_file'].close()
            except Exception as e:
                print(f"æ¸…ç†ç›¸æœº {rec['index']} æ—¶å‡ºé”™: {e}")

        # --- ä¿å­˜ vs ä¸¢å¼ƒ é€»è¾‘ ---
        if save_data_flag:
            print("\nâœ… æ•°æ®å·²ä¿å­˜ã€‚")
            for rec in recorders:
                print(f"  [Cam {rec['index']}] å¸§æ•°: {rec['frame_idx']}")
                print(f"    RGBè§†é¢‘:   {rec['video_path']}")
                print(f"    æ·±åº¦è§†é¢‘:  {rec['depth_video_path']}")
            print(f"  æ•°æ®æ ¹ç›®å½•: {session_dir}")
        else:
            print("\nğŸ—‘ï¸  æ­£åœ¨æ‰§è¡Œåˆ é™¤æ“ä½œ...")
            try:
                if os.path.exists(session_dir):
                    shutil.rmtree(session_dir)
                    print(f"âœ… å·²æˆåŠŸåˆ é™¤æœ¬æ¬¡ä¼šè¯ç›®å½•: {session_dir}")
                else:
                    print("âš ï¸  ç›®å½•ä¸å­˜åœ¨ï¼Œæ— æ³•åˆ é™¤ã€‚")
            except Exception as e:
                print(f"âŒ åˆ é™¤ç›®å½•å¤±è´¥: {e}")

if __name__ == "__main__":
    main()